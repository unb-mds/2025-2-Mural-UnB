# üß™ T√©cnicas de Valida√ß√£o de Modelos no Scikit-Learn

A **valida√ß√£o de modelos** √© essencial para avaliar a **performance** e a **generaliza√ß√£o** de algoritmos de Machine Learning.  
Evita **overfitting** (quando o modelo aprende demais os dados de treino) e garante previs√µes confi√°veis em dados novos.

As principais t√©cnicas incluem:

- **Train/Test Split**  
- **Cross-Validation (K-Fold, Stratified K-Fold)**  
- **Leave-One-Out (LOO)**  
- **Shuffle Split**  

---

## üîπ Train/Test Split

### O que √©?
Divide o dataset em **conjunto de treino** e **conjunto de teste**.  
- Treino ‚Üí modelo aprende padr√µes  
- Teste ‚Üí modelo √© avaliado

### Exemplo em Python
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import numpy as np

# Dados de exemplo
X = np.arange(10).reshape(-1, 1)
y = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17, 19])

# Divis√£o: 70% treino, 30% teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

print("Score no treino:", model.score(X_train, y_train))
print("Score no teste:", model.score(X_test, y_test))
```
> O par√¢metro ***random_state*** garante reprodutibilidade.

## üîπ Cross-Validation (CV)
### O que √©?

1. O dataset √© dividido em K partes (folds).

2. O modelo √© treinado em K-1 folds e testado no fold restante

3. O processo se repete K vezes, cada fold sendo usado como teste uma vez

A m√©dia dos scores fornece uma estimativa mais robusta da performance

### Exemplo com K-Fold
```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
import numpy as np

X = np.arange(10).reshape(-1, 1)
y = np.array([1,3,5,7,9,11,13,15,17,19])

model = LinearRegression()

# 5-Fold Cross-Validation
scores = cross_val_score(model, X, y, cv=5)
print("Scores de cada fold:", scores)
print("M√©dia dos scores:", scores.mean())
```

### Stratified K-Fold

Usado principalmente em **classifica√ß√£o**, mant√©m a **propor√ß√£o de classes** em cada fold.

```python
from sklearn.model_selection import StratifiedKFold

# Exemplo para classifica√ß√£o
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier

iris = load_iris()
X = iris.data
y = iris.target

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
model = RandomForestClassifier()

for train_idx, test_idx in skf.split(X, y):
    model.fit(X[train_idx], y[train_idx])
    score = model.score(X[test_idx], y[test_idx])
    print("Fold score:", score)
```

## üîπ Leave-One-Out (LOO)
### O que √©?

Caso extremo de **cross-validation**:

Cada amostra do dataset √© usada uma vez como teste, o restante como treino

Bom para **datasets pequenos**, mas computacionalmente caro em datasets grandes
```python 
from sklearn.model_selection import LeaveOneOut

loo = LeaveOneOut()
scores = []

for train_idx, test_idx in loo.split(X):
    model.fit(X[train_idx], y[train_idx])
    scores.append(model.score(X[test_idx], y[test_idx]))

print("Score m√©dio LOO:", np.mean(scores))
```

## üîπ Shuffle Split  
### O que √©?  

Gera m√∫ltiplas divis√µes aleat√≥rias de treino/teste, √∫til para validar estabilidade do modelo.
```python
from sklearn.model_selection import ShuffleSplit

ss = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)
scores = cross_val_score(model, X, y, cv=ss)

print("Scores Shuffle Split:", scores)
print("M√©dia:", scores.mean())
```

## üîπ Compara√ß√£o das T√©cnicas

| T√©cnica             | Vantagens                         | Desvantagens                       | Quando Usar                           |
| ------------------- | --------------------------------- | ---------------------------------- | ------------------------------------- |
| Train/Test Split    | Simples, r√°pido                   | Pode depender da divis√£o escolhida | Dados grandes e teste r√°pido          |
| K-Fold CV           | Mais robusto que train/test split | Computacionalmente mais caro       | Avalia√ß√£o mais confi√°vel              |
| Stratified K-Fold   | Mant√©m propor√ß√£o de classes       | Igual ao K-Fold                    | Classifica√ß√£o, classes desbalanceadas |
| Leave-One-Out (LOO) | M√°xima utiliza√ß√£o dos dados       | Muito lento para datasets grandes  | Dados pequenos                        |
| Shuffle Split       | Avalia estabilidade do modelo     | Pode gerar folds semelhantes       | Testes r√°pidos em datasets m√©dios     |

## üîπ Dicas Pr√°ticas
1. Sempre use random_state para resultados reproduz√≠veis.

2. Para datasets pequenos, K-Fold ou LOO s√£o mais confi√°veis.

3. Para datasets grandes, train/test split ou ShuffleSplit s√£o suficientes.

4. Combine com m√©tricas adequadas:

   - Regress√£o ‚Üí R¬≤, MSE, MAE

   - Classifica√ß√£o ‚Üí Accuracy, F1, ROC-AUC

## üîπ Exmplos de Separa√ß√£o de dados

A propor√ß√£o de dados para cada fun√ß√£o varia de caso para caso, mas no geral est√° entre alguma dessa situa√ß√µes: 

<p> <img src="./assets/data_separation.png"/> <p>

<sub>Documenta√ß√£o criada por **Tiago Bittencourt** ([@TiagoSBittencourt](https://github.com/TiagoSBittencourt))</sub>