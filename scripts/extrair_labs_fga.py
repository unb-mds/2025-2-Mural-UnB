"""
Extrai e filtra informa√ß√µes de laborat√≥rios da FGA a partir do PDF (parsing e heur√≠sticas).
Gera CSV com laborat√≥rios da FGA e remove duplicatas/ru√≠do.
"""
import fitz  # PyMuPDF
import re
import csv
import os
import requests                     # Para fazer requisi√ß√µes HTTP (baixar HTML, baixar imagens)
from bs4 import BeautifulSoup       # Para "ler" e navegar pelo HTML das p√°ginas web              # Para montar URLs completas (juntar URL base com caminhos relativos)
import urllib3                      # Usado internamente pelo requests, importamos para controlar avisos
from ddgs import DDGS               # Para fazer buscas na web usando o DuckDuckGo
from unidecode import unidecode     # Para remover acentos de textos (ex: "Rob√≥tica" -> "Robotica")
import time                         # Para adicionar pausas (sleep) no script
import random
from urllib.parse import urljoin, urlparse

# Desabilita avisos sobre certificados SSL inv√°lidos (basicamente, quando certificados s√£o inv√°lidos e tem chance de ser scan)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Diret√≥rio onde este script (extrair_labs_fga.py) est√° localizado
SCRIPT_DIR = os.path.dirname(__file__)
# Caminho completo para a pasta onde as imagens dos laborat√≥rios ser√£o salvas
PASTA_IMAGENS_LABS = os.path.join(SCRIPT_DIR, "..", "data", "images", "labs")
# Este √© o caminho que ser√° salvo no CSV se a busca de imagem falhar.
# O caminho √© relativo √† pasta onde o CSV ser√° salvo (data/Labs/)
CAMINHO_PLACEHOLDER = os.path.join("..", "data", "images", "placeholders", "default_lab.jpg")

# --- FUN√á√ÉO PARA EXTRAIR PALAVRA-CHAVE DO NOME ---

# Lista de palavras comuns (em min√∫sculo e sem acentos) que queremos ignorar
# ao determinar a palavra-chave principal de um laborat√≥rio.
STOP_WORDS = [
    'laboratorio', 'lab', 'de', 'e', 'da', 'do', 'dos', 'das', 'a', 'o',
    'em', 'para', 'com', 'sistemas', 'pesquisa', 'grupo', 'nucleo',
    'centro', 'automacao', 'aplicada', 'aplicados', 'estudos', 'avancados',
    'unb', 'fga'
    # Adicione mais palavras aqui se necess√°rio
]

# --- DICION√ÅRIO PARA CATEGORIZA√á√ÉO DE PLACEHOLDERS ---
CATEGORIAS_KEYWORDS = {
    # Categorias Principais (com 2 varia√ß√µes de placeholder cada)
    "software": [
        "software", "computacao", "computacional", "inform√°tica", "digital",
        "ia", "inteligencia artificial", "algoritmos", "dados", "bioinformatica"
    ],
    "eletronica": [
        "eletronica", "microeletronica", "hardware", "embarcados", "circuitos",
        "semicondutores", "telecomunicacoes"
    ],
    "mecanica_materiais": [ # Agrupa Automotiva, Aero, Energia, Materiais, F√≠sica
        "automotiva", "automotivo", "veicular", "aeroespacial", "aeronautica",
        "energia", "eletrica", "renovaveis", "potencia", "materiais", "nanotecnologia",
        "polimeros", "fisica", "mecanica", "controle", "robotica", "automacao" # Adicionei Rob√≥tica aqui tamb√©m
    ],
    # A fun√ß√£o categorizar_lab retornar√° "default" se nenhuma destas for encontrada
}

# --- FUN√á√ÉO PARA CATEGORIZAR LABORAT√ìRIO ---

def categorizar_lab(nome_do_lab):
    """
    Tenta classificar um laborat√≥rio em uma categoria pr√©-definida
    baseado em palavras-chave encontradas em seu nome.

    Usado para selecionar um placeholder mais relevante quando a busca
    de imagem real falha.

    Args:
        nome_do_lab (str): O nome completo do laborat√≥rio.

    Returns:
        str: O nome da categoria encontrada (ex: "software") ou "default".
    """
    try:
        nome_normalizado = unidecode(nome_do_lab.lower())

        # Itera sobre as categorias e suas palavras-chave definidas globalmente
        for categoria, keywords in CATEGORIAS_KEYWORDS.items():
            # any(...) retorna True se *qualquer* palavra-chave da lista for encontrada no nome
            if any(keyword in nome_normalizado for keyword in keywords):
                return categoria # Retorna o nome da categoria assim que encontrar a primeira correspond√™ncia

    except Exception as e:  # pylint: disable=broad-except
        print(f"    [Categorizar] Erro ao categorizar '{nome_do_lab}': {e}")
        # Em caso de erro, continua para retornar a categoria padr√£o

    # Se nenhum loop encontrou uma correspond√™ncia ou se houve erro
    return "default" # Retorna a categoria padr√£o

def extrair_palavra_chave(nome_do_lab):
    """
    Analisa um nome completo de laborat√≥rio e tenta extrair a palavra
    mais significativa (a "palavra-chave") para usar em buscas web.

    Processo:
    1. Normaliza o nome (min√∫sculas, sem acentos).
    2. Divide em palavras.
    3. Retorna a primeira palavra que n√£o est√° na lista STOP_WORDS e √© longa o suficiente.
    4. Se falhar, retorna a primeira palavra longa.
    5. Se falhar novamente, retorna uma chave gen√©rica "pesquisa".

    Args:
        nome_do_lab (str): O nome completo do laborat√≥rio (ex: "Laborat√≥rio de Rob√≥tica").

    Returns:
        str: A palavra-chave extra√≠da (ex: "robotica").
    """
    try:
        # 1. sem acento e minusculo
        nome_normalizado = unidecode(nome_do_lab.lower())

        # 2. Divide
        palavras = nome_normalizado.split()

        # 3. Filtra usando STOP_WORDS
        for palavra in palavras:
            # Verifica se n√£o √© stop word e tem um tamanho m√≠nimo (evita 'ia', 'ti')
            if palavra not in STOP_WORDS and len(palavra) > 3:
                return palavra # Encontrou a palavra-chave principal

    except Exception as e:  # pylint: disable=broad-except
        # Em caso de erro inesperado durante o processamento do nome
        print(f"    [Palavra Chave] Erro ao extrair chave de '{nome_do_lab}': {e}")
        pass # Continua para retornar a chave gen√©rica

    # 5. Plano C: Chave gen√©rica (√∫ltimo recurso)
    print(f"    [Palavra Chave] N√£o foi poss√≠vel extrair chave de '{nome_do_lab}'. Usando 'pesquisa'.")
    return "pesquisa"

# --- FUN√á√ÉO PARA BAIXAR IMAGEM DA WEB ---

def baixar_imagem(url_imagem, caminho_salvar):
    """
    Tenta baixar um arquivo de imagem a partir de uma URL e salv√°-lo
    no caminho especificado.

    Args:
        url_imagem (str): A URL completa da imagem a ser baixada.
        caminho_salvar (str): O caminho completo no disco onde a imagem
                              deve ser salva (incluindo o nome do arquivo).

    Returns:
        bool: True se o download e salvamento foram bem-sucedidos, False caso contr√°rio.
    """
    try:
        print(f"    [Download] Tentando baixar imagem de: {url_imagem}")
        # Headers para simular um navegador, importante para evitar bloqueios
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}

        # Faz a requisi√ß√£o usando stream=True. Isso √© crucial para arquivos
        # grandes (como imagens), pois baixa o conte√∫do em "peda√ßos"
        # sem carregar tudo na mem√≥ria de uma vez.
        response = requests.get(url_imagem, headers=headers, timeout=15, verify=False, stream=True)
        response.raise_for_status() # Verifica se a URL respondeu com sucesso (status 200 OK)

        # Verifica√ß√£o extra: Checa se o servidor est√° realmente enviando uma imagem
        content_type = response.headers.get('content-type')
        if not content_type or not content_type.startswith('image/'):
             print(f"    [Download] ‚ö†Ô∏è URL n√£o retornou um tipo de conte√∫do de imagem v√°lido (recebido: {content_type}). Pulando download.")
             return False # Aborta se n√£o for uma imagem

        # Garante que a pasta onde a imagem ser√° salva exista.
        # os.path.dirname(caminho_salvar) pega o caminho da pasta (ex: data/images/labs/)
        # exist_ok=True evita erro se a pasta j√° existir.
        os.makedirs(os.path.dirname(caminho_salvar), exist_ok=True)

        # Abre o arquivo local no modo "escrita bin√°ria" ('wb')
        with open(caminho_salvar, 'wb') as f:
            # Itera sobre os "peda√ßos" (chunks) da resposta da imagem
            for chunk in response.iter_content(8192): # L√™ em peda√ßos de 8KB
                if chunk: # Garante que o peda√ßo n√£o est√° vazio
                    f.write(chunk) # Escreve o peda√ßo no arquivo local

        print(f"    [Download] ‚úÖ Imagem salva com sucesso em: {caminho_salvar}")
        return True # Retorna True indicando sucesso

    # Tratamento de erros espec√≠ficos para o download
    except requests.exceptions.Timeout:
        print(f"    [Download] ‚ùå Falha ao baixar {url_imagem}: A requisi√ß√£o demorou demais (Timeout).")
        return False
    except requests.exceptions.RequestException as e:
        # Captura outros erros de conex√£o, URL inv√°lida, etc.
        print(f"    [Download] ‚ùå Falha ao baixar {url_imagem}: {e}")
        return False
    except Exception as e:  # pylint: disable=broad-except
        # Captura erros inesperados ao criar pasta, salvar arquivo, etc.
        print(f"    [Download] ‚ùå Erro inesperado durante o download/salvamento de {url_imagem}: {e}")
        return False

# --- FUN√á√ÉO PRINCIPAL: ENCONTRAR E BAIXAR IMAGEM PARA UM LAB ---

def encontrar_imagem_para_lab(nome_do_lab, pasta_base_imagem):
    """
    Orquestra o processo completo de encontrar uma imagem para um laborat√≥rio:
    1. Extrai a palavra-chave do nome.
    2. Busca na web pela homepage.
    3. Filtra os resultados para achar a URL mais relevante.
    4. Acessa a homepage e procura por uma imagem de destaque ("ca√ßa medalhas").
    5. Se encontrar a URL da imagem, chama a fun√ß√£o para baix√°-la.
    6. Retorna o caminho local da imagem baixada ou None se qualquer etapa falhar.

    Args:
        nome_do_lab (str): O nome completo do laborat√≥rio (vindo do PDF).
        pasta_base_imagem (str): O caminho da pasta onde as imagens baixadas
                                 devem ser salvas (ex: data/images/labs/).

    Returns:
        str or None: O caminho local completo para a imagem baixada
                     (ex: "data/images/labs/robotica.jpg") ou None se falhar.
    """

    URL_BLACKLIST = [
        "bing.com",
        "google.com",
        "escavador.com",
        "researchgate.net",
        "academia.edu",
        "github.com", 
        "linkedin.com",
        "facebook.com",
        "instagram.com",
        "twitter.com",
        "sigaa.unb.br" 
    ]

    IMAGE_FILENAME_BLACKLIST = [
        "logo-unb.png",
        "unbdpi-logo.png",
        "unbpi-logo.png",
        "logo_unb1.png",
        "pctec-unb_logo.png", 
        "repositoriocovid19_header.png", 
        "opine.png",
        "opine-sobre-o-portal.png", 
        "clipart/en.svg", 
        "antonio-150x150.jpg",     
        "cropped-face-12.png",     
        "foto_pessoal_moodles.png", 
        "googleusercontent.com/profile/picture", 
        "grade_curricular_atualizada.png", 
        "benvindo_rodrigues_pereira_junior.jpg",
    ]

    keyword = extrair_palavra_chave(nome_do_lab)

    query_de_busca = f'"{nome_do_lab}" OR site:unb.br "{keyword} FGA"'

    print(f"  [Busca Imagem] Buscando por: {query_de_busca} (chave: {keyword})")

    try:
        resultados_da_busca = []
        # Usa o gerenciador de contexto do DDGS para garantir fechamento
        with DDGS() as ddgs:
            # Faz a busca web, pedindo 5 resultados para o Brasil
            resultados_gen = ddgs.text(query_de_busca, region='br-pt', max_results=5)
            # Converte o gerador (promessa) em uma lista real, se houver resultados
            if resultados_gen:
                resultados_da_busca = list(resultados_gen)

        time.sleep(1.0) # Pausa de cortesia ap√≥s a busca

        if not resultados_da_busca:
             print("    [Busca Imagem] ‚ùå Nenhum resultado encontrado na busca web.")
             return None # Se a busca falhar, n√£o adianta continuar

        # --- FASE 2: FILTRO DE RELEV√ÇNCIA ---
        # --- FASE 2: FILTRO DE RELEV√ÇNCIA (V8 - Com Prioriza√ß√£o e Blacklist) ---
        homepage_url = None
        print(f"    [Busca Imagem] Filtrando resultados por '{keyword}'...")

        url_prioritaria = None
        url_fallback = None
        url_ultimo_recurso = None

        for resultado in resultados_da_busca:
            url_original = resultado['href']
            url_lower = url_original.lower()
            titulo_lower_normalizado = unidecode(resultado['title'].lower())
            
            # 1. Verifica se a URL est√° na Blacklist
            if any(site_ruim in url_lower for site_ruim in URL_BLACKLIST):
                print(f"      [Filtro] Ignorando (Blacklist): {url_original}")
                continue # Pula este resultado, vai para o pr√≥ximo

            # 2. Verifica se √© um link de documento
            if any(ext in url_lower for ext in ['.pdf', '.doc', '.docx', '.odt']):
                print(f"      [Filtro] Ignorando (Documento): {url_original}")
                continue # Pula este resultado

            # 3. Salva o primeiro resultado v√°lido (Plano C)
            if not url_ultimo_recurso:
                url_ultimo_recurso = url_original

            # 4. Verifica a relev√¢ncia da palavra-chave
            keyword_no_titulo = keyword in titulo_lower_normalizado
            keyword_na_url = keyword in url_lower

            if keyword_no_titulo or keyword_na_url:
                # 5. PRIORIDADE M√ÅXIMA: √â da UnB E tem a palavra-chave?
                if ".unb.br" in url_lower:
                    print(f"    [Busca Imagem] üéØ Priorit√°rio (UnB + Chave) encontrado: {url_original}")
                    url_prioritaria = url_original
                    break # Encontramos o melhor, para o loop
                
                # 6. Prioridade M√©dia: N√£o √© da UnB, mas tem a palavra-chave (Plano B)
                if not url_fallback:
                    print(f"    [Busca Imagem] ‚ö†Ô∏è Relevante (Externo + Chave) encontrado: {url_original}")
                    url_fallback = url_original

        # Decide qual URL usar, em ordem de prioridade
        if url_prioritaria:
            homepage_url = url_prioritaria   # 1¬∫: UnB + Palavra-Chave
        elif url_fallback:
            homepage_url = url_fallback      # 2¬∫: Externo + Palavra-Chave
        elif url_ultimo_recurso:
            homepage_url = url_ultimo_recurso # 3¬∫: Primeiro link que n√£o estava na blacklist
        else:
            print("    [Busca Imagem] ‚ùå Nenhum resultado web parece ser uma homepage v√°lida (todos na blacklist?).")
            return None # Desiste

# --- FASE 3: CA√áA √Ä IMAGEM (V11 - Prioriza√ß√£o e Blacklist Aprimorada) ---
        print(f"    [Busca Imagem] Ca√ßando imagem em: {homepage_url}")
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
            response_lab = requests.get(homepage_url, headers=headers, timeout=15, verify=False)
            response_lab.raise_for_status() 

            soup_lab = BeautifulSoup(response_lab.content, 'html.parser')
            url_imagem_encontrada = None 

            # --- Fun√ß√£o helper V11 (agora interna da FASE 3) ---
            def is_url_valida(url_teste):
                if not url_teste:
                    return False
                url_lower = url_teste.lower()

                # 1. Rejeita 'data:' URIs (imagens embutidas que 'requests' n√£o baixa)
                if url_lower.startswith('data:'):
                    print(f"      [Ca√ßa] ‚ö†Ô∏è Rejeitado (Data URI): {url_teste[:60]}...")
                    return False

                # 2. Rejeita se for SVG
                if url_lower.endswith('.svg'):
                    print(f"      [Ca√ßa] ‚ö†Ô∏è Rejeitado (SVG): {url_teste}")
                    return False

                # 3. Rejeita se estiver na blacklist de nomes de arquivo
                if any(nome_ruim in url_lower for nome_ruim in IMAGE_FILENAME_BLACKLIST):
                    print(f"      [Ca√ßa] ‚ö†Ô∏è Rejeitado (Blacklist Nome): {url_teste}")
                    return False

                return True
            # --- Fim da fun√ß√£o helper ---

            # Alvo #1 (Ouro): Tag <meta property="og:image"> - SEMPRE A MAIOR PRIORIDADE
            meta_og_image = soup_lab.find('meta', property='og:image')
            if meta_og_image and meta_og_image.get('content'):
                url_teste = meta_og_image.get('content')
                if is_url_valida(url_teste):
                    url_imagem_encontrada = url_teste
                    print("      [Ca√ßa] ü•á Ouro ('og:image')")

            # Alvo #2 (Verde): Primeira imagem GRANDE dentro do conte√∫do principal (priorizar fotos de labs)
            # Busca agressiva por uma imagem que tenha pelo menos 200x200px
            if not url_imagem_encontrada:
                seletores_conteudo = ['main', 'article', 'div[class*="content"]', 'div[class*="post"]', 'body']
                for seletor in seletores_conteudo:
                    area_conteudo = soup_lab.select_one(seletor)
                    if area_conteudo:
                        for img_conteudo in area_conteudo.find_all('img'):
                            if img_conteudo and img_conteudo.get('src'):
                                url_teste = img_conteudo.get('src')
                                if is_url_valida(url_teste):
                                    # Tenta obter dimens√µes diretamente da tag, se existirem
                                    width_str = img_conteudo.get('width', '0').replace('px', '')
                                    height_str = img_conteudo.get('height', '0').replace('px', '')

                                    try:
                                        width = int(width_str)
                                        height = int(height_str)
                                        # MUDAN√áA: Exige tamanho m√≠nimo maior para conte√∫do (200x200)
                                        if width >= 200 and height >= 200: 
                                            url_imagem_encontrada = url_teste
                                            print(f"      [Ca√ßa] üíö Verde ('{seletor}' img >= 200px)")
                                            break 
                                    except ValueError:
                                        # Se width/height n√£o s√£o ints, pode ser que as dims n√£o estejam na tag,
                                        # tentamos com o proximo loop
                                        pass
                            if url_imagem_encontrada: break 
                    if url_imagem_encontrada: break 

            # Alvo #3 (Prata): Imagem de Logo no Header (apenas se n√£o achou og:image ou foto de conte√∫do)
            # Este √© mais um fallback para logos da homepage, n√£o de labs espec√≠ficos
            if not url_imagem_encontrada:
                seletores_logo = [
                    'img[id*="logo"]', 'img[class*="logo"]', 'img[src*="logo"]',
                    'img[id*="brand"]', 'img[class*="brand"]'
                ]
                for seletor in seletores_logo:
                    logo_img = soup_lab.select_one(seletor)
                    if logo_img and logo_img.get('src'):
                        url_teste = logo_img.get('src')

                        # NOVO: Extrai o dom√≠nio da homepage_url para verifica√ß√£o
                        domain_homepage = urlparse(homepage_url).netloc

                        if is_url_valida(url_teste):
                            # MUDAN√áA V12: Se a URL da homepage N√ÉO FOR .unb.br E a imagem contiver "logo" no nome, REJEITAR.
                            # Isso evita pegar logos de outras universidades (ex: UFPE) como imagem para um lab da UnB.
                            if not domain_homepage.endswith('.unb.br') and "logo" in url_teste.lower():
                                print(f"      [Ca√ßa] ‚ö†Ô∏è Rejeitado (Logo Externo): {url_teste}")
                                continue # Pula esta imagem e tenta a pr√≥xima

                            width_str = logo_img.get('width', '0').replace('px', '')
                            height_str = logo_img.get('height', '0').replace('px', '')
                            try:
                                # Exige tamanho m√≠nimo de 50px para logos
                                if int(width_str) > 50 or int(height_str) > 50: 
                                    url_imagem_encontrada = url_teste
                                    print(f"      [Ca√ßa] ü•à Prata (Logo '{seletor}')")
                                    break
                            except ValueError: pass

            # Alvo #4 (Bronze): Primeira imagem maior que 100x100px dentro do <header> ou de um 'banner' (√∫ltimo recurso)
            if not url_imagem_encontrada:
                header = soup_lab.find('header')
                if header:
                    for img_header in header.find_all('img'): # Busca todas as imgs no header
                        if img_header and img_header.get('src'):
                            url_teste = img_header.get('src')
                            if is_url_valida(url_teste):
                                width_str = img_header.get('width', '0').replace('px', '')
                                height_str = img_header.get('height', '0').replace('px', '')
                                try:
                                    # MUDAN√áA: Exige 100x100px para imgs no header/banner
                                    if int(width_str) > 100 and int(height_str) > 100: 
                                        url_imagem_encontrada = url_teste
                                        print("      [Ca√ßa] ü•â Bronze (<header> img > 100px)")
                                        break
                                except ValueError: pass
                        if url_imagem_encontrada: break

                if not url_imagem_encontrada:
                    banner = soup_lab.find('div', class_=lambda x: x and 'banner' in x.lower())
                    if banner:
                        for img_banner in banner.find_all('img'): # Busca todas as imgs no banner
                            if img_banner and img_banner.get('src'):
                                url_teste = img_banner.get('src')
                                if is_url_valida(url_teste):
                                    width_str = img_banner.get('width', '0').replace('px', '')
                                    height_str = img_banner.get('height', '0').replace('px', '')
                                    try:
                                        if int(width_str) > 100 and int(height_str) > 100: 
                                            url_imagem_encontrada = url_teste
                                            print("      [Ca√ßa] ü•â Bronze (banner div img > 100px)")
                                            break
                                    except ValueError: pass
                            if url_imagem_encontrada: break

            # --- FASE 4: DOWNLOAD E RETORNO DO RESULTADO ---
            if url_imagem_encontrada:
                url_imagem_completa = urljoin(homepage_url, url_imagem_encontrada)

                nome_base = "".join(c for c in keyword if c.isalnum() or c in ('_')).rstrip()
                nome_prefixo = "".join(c for c in nome_do_lab if c.isalnum())[:3].lower()
                nome_arquivo = f"{nome_prefixo}_{nome_base}.jpg" 

                caminho_local_salvar = os.path.join(pasta_base_imagem, nome_arquivo)

                # Chama a fun√ß√£o de download
                if baixar_imagem(url_imagem_completa, caminho_local_salvar):
                    return caminho_local_salvar # SUCESSO!

            else:
                 print("      [Ca√ßa] ‚ùå Nenhuma imagem encontrada na p√°gina ap√≥s todas as tentativas.")

        # Erros da "Ca√ßa" (Fase 3)
        except requests.exceptions.Timeout: # <--- N√çVEL 2 (ALINHADO COM O TRY INTERNO)
             print(f"    [Busca Imagem] ‚ùå Timeout ao acessar homepage {homepage_url}.")
        except requests.exceptions.RequestException as e: # <--- N√çVEL 2 (ALINHADO COM O TRY INTERNO)
            print(f"    [Busca Imagem] ‚ùå Erro de conex√£o/HTTP ao acessar homepage {homepage_url}: {e}")
        
        # --- LINHA DO ERRO ---
        # Esta linha deve estar no N√çVEL 1, (ALINHADA COM O TRY EXTERNO)
        print("    [Busca Imagem] ‚ùå Falha geral ao encontrar/baixar imagem para este laborat√≥rio.")
        return None 

    except Exception as e:  # pylint: disable=broad-except
        print(f"    [Busca Imagem] ‚ùå Erro inesperado durante o processo: {e}")
        return None

def limpar_texto(texto):
    """
    Remove caracteres especiais problem√°ticos do texto
    """
    if not texto:
        return texto
    # Remove espa√ßos n√£o-quebr√°veis e outros caracteres Unicode problem√°ticos
    texto = texto.replace('\u202f', ' ')  # Narrow no-break space
    texto = texto.replace('\xa0', ' ')    # Non-breaking space
    texto = texto.replace('\u2013', '-')  # En dash
    texto = texto.replace('\u2014', '-')  # Em dash
    texto = texto.replace('\u2019', "'")  # Right single quotation mark
    texto = texto.replace('\u201c', '"')  # Left double quotation mark
    texto = texto.replace('\u201d', '"')  # Right double quotation mark
    return texto

def juntar_palavras_hifenizadas(texto):
    """
    Remove hifeniza√ß√£o de quebra de linha
    Exemplo: 'pesqui- sadores' -> 'pesquisadores'
    """
    if not texto:
        return texto
    # Padr√£o: letra + h√≠fen + espa√ßo(s) + letra min√∫scula
    # Isso indica quebra de palavra no final da linha
    texto = re.sub(r'(\w)-\s+(\w)', r'\1\2', texto)
    return texto

def extrair_laboratorios_fga_pdf(pdf_path, pagina_inicial=13):
    doc = fitz.open(pdf_path)
    idx_inicial = pagina_inicial - 1
    texto_completo = ""
    for num_pagina in range(idx_inicial, len(doc)):
        texto_pagina = doc[num_pagina].get_text()
        # Limpa caracteres especiais
        texto_completo += limpar_texto(texto_pagina)
    doc.close()
    # Lista para armazenar laborat√≥rios
    laboratorios = []
    labs_fga = []
    # Divide o texto em linhas para an√°lise
    linhas = texto_completo.split('\n')
    lab_atual = None
    i = 0
    while i < len(linhas):
        linha = linhas[i].strip()
        if not linha:
            i += 1
            continue
        
        # VERIFICA CABE√áALHOS DE SE√á√ÉO (antes de processar laborat√≥rios)
        if (re.match(r'^\d+\.\d+(\.\d+)*\.', linha) or  # Numera√ß√£o de se√ß√£o (1.2.5.)
            re.match(r'^[_\-]{20,}$', linha)):  # Linha de separa√ß√£o longa
            # Salva o laborat√≥rio atual se existir
            if lab_atual:
                laboratorios.append(lab_atual)
                texto_completo_lab = f"{lab_atual['nome']} {lab_atual['coordenador']} {lab_atual['contato']} {lab_atual['descricao']}"
                if 'FGA' in texto_completo_lab.upper():
                    labs_fga.append(lab_atual)
                lab_atual = None
            i += 1
            continue
        
        # CASO ESPECIAL: N√∫mero sozinho em uma linha (labs 1-9)
        if re.match(r'^(\d+)\.$', linha):
            numero_lab = re.match(r'^(\d+)\.$', linha).group(1)
            if i + 1 < len(linhas):
                proxima_linha = linhas[i + 1].strip()
                if (proxima_linha and 
                    not proxima_linha.startswith('COORDENADOR:') and
                    not proxima_linha.startswith('COORDENADORES:') and
                    not proxima_linha.startswith('CONTATO:') and
                    not proxima_linha.startswith('DESCRI√á√ÉO:') and
                    not proxima_linha.startswith('DESCRICAO:')):
                    # Salva o laborat√≥rio anterior se existir
                    if lab_atual:
                        laboratorios.append(lab_atual)
                        # Verifica se √© da FGA
                        texto_completo_lab = f"{lab_atual['nome']} {lab_atual['coordenador']} {lab_atual['contato']} {lab_atual['descricao']}"
                        if 'FGA' in texto_completo_lab.upper():
                            labs_fga.append(lab_atual)
                    # Cria novo laborat√≥rio
                    lab_atual = {
                        'nome': proxima_linha,
                        'coordenador': '',
                        'contato': '',
                        'descricao': ''
                    }
                    i += 2
                    continue
        
        # CASO NORMAL: N√∫mero e nome na mesma linha (labs 10+)
        padrao_numero_simples = re.match(r'^(\d+)\.\s+(.+)', linha)
        if padrao_numero_simples:
            numero_lab = padrao_numero_simples.group(1)
            nome_sem_numero = padrao_numero_simples.group(2).strip()
            # FILTRO 1: Rejeita sub-numera√ß√£o
            if re.match(r'^\d+\.\d+', linha):
                i += 1
                continue

            # FILTRO 2: Rejeita cabe√ßalhos em MAI√öSCULAS
            palavras_significativas = [p for p in nome_sem_numero.split() 
                                       if len(p) > 2 and p.isalpha()]
            if palavras_significativas:
                maiusculas = sum(1 for p in palavras_significativas if p.isupper())
                if maiusculas / len(palavras_significativas) > 0.7:
                    i += 1
                    continue

            # Aceita se tiver pelo menos 10 caracteres e menos de 200
            if len(nome_sem_numero) > 10 and len(nome_sem_numero) < 200:
                # Se o nome termina com h√≠fen, verifica se a sigla est√° na pr√≥xima linha
                if nome_sem_numero.endswith('-') and i + 1 < len(linhas):
                    proxima = linhas[i + 1].strip()
                    # Se a pr√≥xima linha √© curta (prov√°vel sigla) e n√£o √© um campo, adiciona ao nome
                    if (proxima and len(proxima) < 30 and 
                        not proxima.startswith('COORDENADOR:') and
                        not proxima.startswith('COORDENADORES:') and
                        not proxima.startswith('CONTATO:') and
                        not proxima.startswith('DESCRI√á√ÉO:') and
                        not proxima.startswith('DESCRICAO:')):
                        nome_sem_numero += ' ' + proxima
                        i += 1  # Pula a pr√≥xima linha j√° que foi incorporada
                # Salva o laborat√≥rio anterior se existir
                if lab_atual:
                    laboratorios.append(lab_atual)
                    # Verifica se √© da FGA
                    texto_completo_lab = f"{lab_atual['nome']} {lab_atual['coordenador']} {lab_atual['contato']} {lab_atual['descricao']}"
                    if 'FGA' in texto_completo_lab.upper():
                        labs_fga.append(lab_atual)
                # Cria novo laborat√≥rio
                lab_atual = {
                    'nome': nome_sem_numero,
                    'coordenador': '',
                    'contato': '',
                    'descricao': ''
                }
        # Se estamos rastreando um laborat√≥rio, tenta preencher informa√ß√µes
        elif lab_atual:
            # COORDENADOR ou COORDENADORES (singular e plural)
            if (linha.startswith('COORDENADOR:') or 
                linha.startswith('COORDENADORES:') or 
                linha.startswith('RESPONS√ÅVEL:') or
                linha.startswith('RESPONS√ÅVEIS:')):
                coordenador_texto = linha.split(':', 1)[1].strip() if ':' in linha else ''
                # Remove todos os IDs Lattes (pode haver m√∫ltiplos)
                coordenador_texto = re.sub(r'\s*\(ID Lattes:\s*\d+\)', '', coordenador_texto, flags=re.IGNORECASE)
                # Remove IDs Lattes incompletos (casos onde o par√™ntese fecha em outra linha)
                coordenador_texto = re.sub(r'\s*\(ID\s*$', '', coordenador_texto)
                coordenador_texto = re.sub(r'\s*\(ID Lattes:.*$', '', coordenador_texto)
                # Se j√° existe um coordenador, adiciona o novo separado por v√≠rgula
                if lab_atual['coordenador']:
                    lab_atual['coordenador'] += ', ' + coordenador_texto.strip()
                else:
                    lab_atual['coordenador'] = coordenador_texto.strip()
            # CONTATO
            elif linha.startswith('CONTATO:'):
                lab_atual['contato'] = linha.split(':', 1)[1].strip() if ':' in linha else ''
            # DESCRI√á√ÉO
            elif linha.startswith('DESCRI√á√ÉO:') or linha.startswith('DESCRICAO:'):
                descricao = linha.split(':', 1)[1].strip() if ':' in linha else ''
                # Captura descri√ß√£o em m√∫ltiplas linhas
                j = i + 1
                while j < len(linhas):
                    proxima_linha = linhas[j].strip()
                    # Verifica se encontrou cabe√ßalho de se√ß√£o (termina processamento do lab atual)
                    if proxima_linha and re.match(r'^\d+\.\d+(\.\d+)*\.', proxima_linha):
                        break
                    
                    # Para se encontrar uma nova se√ß√£o ou marcadores de fim
                    if proxima_linha and (':' in proxima_linha and 
                        any(proxima_linha.startswith(palavra) for palavra in 
                            ['GRUPOS', 'EQUIPAMENTOS', 'COORDENADOR', 'COORDENADORES', 
                             'CONTATO', 'LABORAT√ìRIO', 'N√öCLEO', 'CENTRO'])):
                        break

                    # Para se encontrar marcadores de rodap√© ou nova se√ß√£o
                    if proxima_linha:
                        # Detecta in√≠cio de se√ß√£o (letra + h√≠fen + mai√∫sculas)
                        if re.match(r'^[IVX]+\s*-\s*[A-Z√Ä√Å√Ç√É√â√ä√ç√ì√î√ï√ö√á\s]+$', proxima_linha):
                            break
                        # Detecta rodap√© institucional
                        if any(palavra in proxima_linha.upper() for palavra in 
                               ['UNIVERSIDADE DE BRAS√çLIA', 'PORTF√ìLIO', 'INFRAESTRUTURA DE PESQUISA', 
                                'DPI CPAIP', 'CI√äNCIAS EXATAS E TECNOL√ìGICAS', 'CI√äNCIAS EXATAS E DA TERRA']):
                            break

                        # Detecta linhas de separa√ß√£o (muitos underscores ou h√≠fens)
                        if re.match(r'^[_\-]{10,}$', proxima_linha):
                            break

                        descricao += ' ' + proxima_linha
                    j += 1
                # Remove classifica√ß√£o
                descricao = re.sub(r'\s+CLASSIFICA[√áC][√ÉA]O:.*$', '', descricao, flags=re.IGNORECASE)
                descricao = re.sub(r'\s+Laborat[√≥o]rio de Pesquisa\s*$', '', descricao, flags=re.IGNORECASE)
                # Remove fragmentos de rodap√© que podem ter sido capturados
                descricao = re.sub(r'\s+[IVX]+\s*-\s*CI√äNCIAS.*$', '', descricao, flags=re.IGNORECASE)
                descricao = re.sub(r'\s+UNIVERSIDADE DE BRAS√çLIA.*$', '', descricao, flags=re.IGNORECASE)
                descricao = re.sub(r'\s+PORTF√ìLIO.*$', '', descricao, flags=re.IGNORECASE)
                # Remove hifeniza√ß√£o de quebra de linha
                descricao = juntar_palavras_hifenizadas(descricao)
                lab_atual['descricao'] = descricao.strip()
                i = j - 1
        i += 1
    # Adiciona o √∫ltimo laborat√≥rio
    if lab_atual:
        laboratorios.append(lab_atual)
        texto_completo_lab = f"{lab_atual['nome']} {lab_atual['coordenador']} {lab_atual['contato']} {lab_atual['descricao']}"
        if 'FGA' in texto_completo_lab.upper():
            labs_fga.append(lab_atual)
    return labs_fga

def filtrar_labs_fga(pdf_path, csv_saida):
    # Extrai laborat√≥rios da FGA do PDF
    labs_fga = extrair_laboratorios_fga_pdf(pdf_path)
    # Detecta quando a descri√ß√£o menciona um lab diferente do nome
    labs_fga_filtrados = []
    for lab in labs_fga:
        # Se a descri√ß√£o menciona FGA, OK
        if 'FGA' in lab['descricao'].upper():
            # Verifica se a descri√ß√£o fala de um lab diferente
            nome_curto = lab['nome'].split('-')[0].strip().split()[0:3]  # Primeiras palavras do nome
            primeira_frase_desc = lab['descricao'].split('.')[0] if lab['descricao'] else ""
            nome_keywords = [palavra.lower() for palavra in nome_curto if len(palavra) > 3]
            desc_lower = primeira_frase_desc.lower()
            # Verifica se pelo menos uma palavra do nome aparece na descri√ß√£o
            tem_match = any(keyword in desc_lower for keyword in nome_keywords)
            sigla_match = re.match(r'^O\s+([A-Z]+),', primeira_frase_desc)
            if sigla_match:
                sigla_desc = sigla_match.group(1)
                if sigla_desc not in lab['nome']:
                    continue

            labs_fga_filtrados.append(lab)
    # Remove duplicatas baseando-se no nome do laborat√≥rio
    labs_unicos = {}
    for lab in labs_fga_filtrados:
        nome_normalizado = lab['nome'].strip().upper()
        if nome_normalizado not in labs_unicos:
            labs_unicos[nome_normalizado] = lab
    labs_fga_sem_id = list(labs_unicos.values())
    print()
    print(f"RESULTADO: {len(labs_fga_sem_id)} laboratorios da FGA ")
    print()

    # --- PASSO 1: ENRIQUECIMENTO COM IMAGENS (O SEU C√ìDIGO) ---
    # (Usa 'labs_fga_sem_id' como entrada)
    print(f"\n--- Iniciando busca de imagens para os {len(labs_fga_sem_id)} laborat√≥rios FGA encontrados ---")
    labs_enriquecidos = [] # Nova lista para guardar os labs com imagem

    for lab in labs_fga_sem_id: # <--- USA A VARI√ÅVEL DA 'main'
        print(f"\n---> Buscando imagem para: {lab['nome']}")
        caminho_imagem_local = encontrar_imagem_para_lab(lab['nome'], PASTA_IMAGENS_LABS)

        if caminho_imagem_local:
            lab['caminho_imagem'] = os.path.join("..", "images", "labs", os.path.basename(caminho_imagem_local))
            print(f"---> Imagem associada: {lab['caminho_imagem']}")
        else:
            categoria = categorizar_lab(lab['nome']) 
            if categoria in ["software", "eletronica", "mecanica_materiais", "default"]:
                numero_variacao = random.randint(1, 3)
                nome_placeholder = f"{categoria}_{numero_variacao}.jpg"
            else:
                numero_variacao = 1
                nome_placeholder = f"default_{numero_variacao}.jpg"
                categoria = "default"
            lab['caminho_imagem'] = os.path.join("..", "data", "images", "placeholders", nome_placeholder)
            print(f"---> Usando placeholder ({categoria} varia√ß√£o {numero_variacao}): {lab['caminho_imagem']}")

        labs_enriquecidos.append(lab) # Adiciona o lab (com imagem ou placeholder)
        time.sleep(1.5) 

    print("\n--- Busca de imagens conclu√≠da ---")

    # --- PASSO 2: GERA√á√ÉO DE IDS (O C√ìDIGO DELES, DA MAIN) ---
    # (Usa 'labs_enriquecidos' como entrada)
    print("Gerando IDs √∫nicos para os laborat√≥rios...")
    labs_final_com_id = [] # Esta ser√° a nova lista final com IDs

    for i, lab in enumerate(labs_enriquecidos): # <--- USA A LISTA ENRIQUECIDA
        contador = i + 1
        id_lab = f"2{contador:05d}" 

        # Cria um novo dicion√°rio com o ID como primeiro campo
        lab_atualizado = {'id': id_lab, **lab}

        # Adiciona √† nova lista final
        labs_final_com_id.append(lab_atualizado)

    print(f"‚úì IDs gerados para {len(labs_final_com_id)} laborat√≥rios.")

    # --- PASSO 3: SALVAR O CSV (A VERS√ÉO COMBINADA) ---
    if labs_final_com_id: # Verifica a lista final com IDs e Imagens
        # Salva no CSV de sa√≠da
        with open(csv_saida, 'w', newline='', encoding='utf-8') as f:
            # A lista de campos COMPLETA (a sua + a deles)
            campos = ['id', 'nome', 'coordenador', 'contato', 'descricao', 'caminho_imagem']
            writer = csv.DictWriter(f, fieldnames=campos)
            writer.writeheader()
            # Escreve a lista FINAL
            writer.writerows(labs_final_com_id)

def main():
    # Caminhos
    script_dir = os.path.dirname(__file__)
    pdf_path = os.path.join(script_dir, "..", "data", "Labs", "Portfolio_Infraestrutura_UnB.pdf")
    csv_saida = os.path.join(script_dir, "..", "data", "Labs", "labs_fga.csv")
    # Verifica se o PDF existe
    if not os.path.exists(pdf_path):
        print(f"ERRO: PDF n√£o encontrado em {pdf_path}")
        print("Baixe o PDF primeiro executando o script labs_pdf.py")
        return
    
    try:
        filtrar_labs_fga(pdf_path, csv_saida)
    except Exception as e:  # pylint: disable=broad-except
        print(f"\nERRO: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
